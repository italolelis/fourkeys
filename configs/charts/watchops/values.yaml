serviceAccount:
  # -- Specifies whether a ServiceAccount should be created
  create: true
  # -- The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name: null
  # -- Image pull secrets for the service account
  imagePullSecrets: []
  # -- Annotations for the service account
  annotations: {}
  # -- Set this toggle to false to opt out of automounting API credentials for the service account
  automountServiceAccountToken: false

rbac:
  create: true
  pspEnabled: true

pdb:
  enabled: true
  minAvailable: 1

networkPolicy:
  # -- Whether to enable network policies. If your cluster supports it, I recommend enabling it.
  enabled: false
  # ingress:
  #   namespaceSelector: {}
  # alertmanager:
  #   port: null

autoscaling:
  publisher:
    # -- Enable autoscaling for the Four Keys main API.
    enabled: false
    # -- Number of minimum replicas to scale down.
    minReplicas: 1
    # -- Number of maximum replicas to scale up.
    maxReplicas: 3
    # -- Target CPU utilization percentage.
    targetCPUUtilizationPercentage: 80
    # -- Target memory utilization percentage.
    targetMemoryUtilizationPercentage: 50

publisher:
  enabled: true
  image:
    repository: "ghcr.io/italolelis/watchops-publisher"
    tag: latest
  imagePullSecrets: []
  replicaCount: 1
  labels: {}
  annotations: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  livenessProbe:
    httpGet:
      path: /live
      port: http-probe
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  readinessProbe:
    httpGet:
      path: /ready
      port: http-probe
    initialDelaySeconds: 15
    periodSeconds: 10
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 3
  resources:
    requests:
      cpu: 20m
      memory: 30Mi
    # limits:
    #   cpu: 50m
    #   memory: 50Mi
  config:
    # -- Configure the port number of the main API.
    port: 8080
    # -- Define the log level. Accepted values are: debug, info, warn, error.
    logLevel: "info"
    # -- Sets the github secret that will be use to validate incoming webhooks from GitHub.
    githubSecret: ""
    # -- Sets the OpsGenie secret that will be used to validate incoming webhooks from OpsGenie.
    opsgenieSecret: ""
    rest:
      # -- Defines the read server timeout.
      readTimeout: "30s"
      # -- Defines the write server timeout.
      writeTimeout: "30s"
      # -- Defines the idle server timeout.
      idleTimeout: "30s"
    messageBroker:
      # -- Defines which message broker to use. You can choose between pubsub, kinesis or awslambda (which is also based on kinesis).
      driver: "pubsub"
      # -- If you defined multiple topics (one for each incoming webhook type), then you can define the prefix of these topics.
      topicPrefix: "watchops-github"
      pubsub:
        # -- The project ID to use pubsub.
        projectID: ""
        # -- The publisher timeout. Defualts to 5s.
        publisherTimeout: 5s
      kinesis:
        # -- Defines the timeout to call kinesis.
        timeout: 5s
        # -- Defines the number of HTTP retries in case a kinesis request fails.
        maxRetries: 3

subscribers:
  github:
    enabled: true
    image:
      repository: "ghcr.io/italolelis/watchops-subscriber"
      tag: latest
    imagePullSecrets: []
    replicaCount: 1
    labels: {}
    annotations: {}
    nodeSelector: {}
    affinity: {}
    tolerations: []
    podAnnotations: {}
    podSecurityContext: {}
    securityContext: {}
    livenessProbe: {}
    readinessProbe: {}
    resources:
      requests:
        cpu: 20m
        memory: 30Mi
      # limits:
      #   cpu: 50m
      #   memory: 50Mi
    config:
      # -- Define the log level. Accepted values are: debug, info, warn, error.
      logLevel: "info"
      database:
        # -- The main database driver (the event store). You can choose between biquery, postgres or redshift.
        driver: "bigquery"
        # -- The DSN for the database.
        dsn: ""
        bigquery:
          # -- The project ID to use bigquery.
          projectID: ""
      messageBroker:
        # -- Defines which message broker to use. You can choose between pubsub, kinesis or awslambda (which is also based on kinesis).
        driver: "pubsub"
        pubsub:
          # -- The project ID to use pubsub.
          projectID: ""
          # -- The name of the pubsub subscription.
          subscription: "watchops-github"
        kinesis:
          # -- Defines the timeout to call kinesis.
          timeout: 5s
          # -- Defines the number of HTTP retries in case a kinesis request fails.
          maxRetries: 3
          # -- Sets the name of the stream this subscriber will listen to. If you are using a single stream for all webhook types, then just define the name of that stream.
          streamName: "watchops_github"
          # -- When using AWS Kinesis, you need to set the AWS region.
          region: "eu-central-1"
        store:
          # -- The message broker storage that holds the last read record from the broker. You can choose between memory, postgres, mysql, or redis. I do not recommend using the memory store in production.
          driver: "memory"
          # -- The app name that is used as a namespace in the storage.
          appName: "watchops-consumer-github"
          postgres:
            # -- The postgres table name.
            tableName: "kinesis_consumer"
            # -- The postgres database DSN. If you are using the postgres chart, you don't need to define this value.
            dsn: ""
          mysql:
            # -- The mysql table name.
            tableName: "kinesis_consumer"
            # -- The mysql database DSN. If you are using the mysql chart, you don't need to define this value.
            dsn: ""
          redis:
            # -- The redis address. If you are using the redis chart, you don't need to define this value.
            address: ""
            # -- The redis database. If you are using the redis chart, you don't need to define this value.
            db: ""
            # -- The redis username. If you are using the redis chart, you don't need to define this value.
            username: ""
            # -- The redis password. If you are using the redis chart, you don't need to define this value.
            password: ""

service:
  type: ClusterIP
  port: 80
  probePort: 9090

ingress:
  # -- Enables Ingress
  enabled: false
  # -- Ingress annotations (values are templated)
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  # -- Ingress accepted hostnames
  hosts:
    - host: chart-example.local
      paths:
        - '/'
      backend:
        serviceName: chart-example.local
        servicePort: 80
  # -- Ingress TLS configuration
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

migrations:
  # -- Enable migrations to your datasource.
  enabled: false
  labels: {}
  # source: github://${{ secrets.MIGRATIONS_SOURCE_CRED }}@italolelis/watchops/configs/migrations/postgres
  # destination: redshift://${{ secrets.MIGRATIONS_DESTINATION_CRED }}@localhost:5432/watchops?sslmode=disable\

# Enable this if you're using https://github.com/coreos/prometheus-operator
serviceMonitor:
  # -- Whether to enable prometheus service monitor. Enable this if you're using https://github.com/coreos/prometheus-operator.
  enabled: false

# Rules for the Prometheus Operator
prometheusRule:
  # -- If enabled, a PrometheusRule resource for Prometheus Operator is created
  enabled: false
  # -- Alternative namespace for the PrometheusRule resource
  namespace: null
  # -- PrometheusRule annotations
  annotations: {}
  # -- Additional PrometheusRule labels
  labels: {}
  # -- Contents of Prometheus rules file
  groups: []
  # - name: watchops-rules
  #   rules:
  #     - record: job:loki_request_duration_seconds_bucket:sum_rate
  #       expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, job)
  #     - record: job_route:loki_request_duration_seconds_bucket:sum_rate
  #       expr: sum(rate(loki_request_duration_seconds_bucket[1m])) by (le, job, route)
  #     - record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
  #       expr: sum(rate(container_cpu_usage_seconds_total[1m])) by (node, namespace, pod, container)
